{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "try:\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    test_df = pd.read_csv('test.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Make sure 'train.csv' and 'test.csv' are uploaded to your Colab session.\")\n",
        "\n",
        "    exit()\n",
        "\n",
        "\n",
        "\n",
        "if 'SalePrice' in train_df.columns:\n",
        "    y_train = train_df['SalePrice']\n",
        "    train_df = train_df.drop('SalePrice', axis=1)\n",
        "else:\n",
        "    print(\"Target variable 'SalePrice' not found in train.csv. Please check the dataset.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "ntrain = train_df.shape[0]\n",
        "all_data = pd.concat((train_df, test_df), sort=False).reset_index(drop=True)\n",
        "\n",
        "\n",
        "all_data = all_data.drop('Id', axis=1)\n",
        "\n",
        "\n",
        "categorical_features = all_data.select_dtypes(include=['object']).columns\n",
        "numerical_features = all_data.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore')) # Handle unseen categories\n",
        "])\n",
        "\n",
        "# Create a column transformer to apply different transformations to different column types\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Apply the preprocessing steps\n",
        "all_data_processed = preprocessor.fit_transform(all_data)\n",
        "\n",
        "# Split back into train and test sets\n",
        "X_train_processed = all_data_processed[:ntrain]\n",
        "X_test_processed = all_data_processed[ntrain:]\n",
        "\n",
        "print(\"Preprocessing and Feature Engineering Complete.\")\n",
        "print(f\"Shape of processed training data: {X_train_processed.shape}\")\n",
        "print(f\"Shape of processed test data: {X_test_processed.shape}\")\n",
        "print(f\"Shape of training target variable: {y_train.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QUnA4cpOZrO",
        "outputId": "01afd8e3-879e-4eb0-ca6a-9a8ddb1fe0d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Preprocessing and Feature Engineering Complete.\n",
            "Shape of processed training data: (1460, 310)\n",
            "Shape of processed test data: (1459, 310)\n",
            "Shape of training target variable: (1460,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "po2xIjZLQt8S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}